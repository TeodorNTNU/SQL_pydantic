{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create the OpenAI LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database reset complete.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Date\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base, Session\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# Database URL and Base declarative class\n",
    "SQLALCHEMY_DATABASE_URL = 'sqlite:///./api_data.db'\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the ElectricityData model\n",
    "class ElectricityData(Base):\n",
    "    __tablename__ = 'electricity_prices'\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    city = Column(String, index=True)\n",
    "    state = Column(String, index=True)\n",
    "    date = Column(Date, index=True)\n",
    "    region = Column(String, index=True)\n",
    "    NOK_per_kWh = Column(Float)\n",
    "    EUR_per_kWh = Column(Float)\n",
    "    EXR = Column(Float)\n",
    "    time_start = Column(String)\n",
    "    time_end = Column(String)\n",
    "    timestamp = Column(DateTime, default=datetime.datetime.now(datetime.timezone.utc))\n",
    "\n",
    "# Define the WeatherData model\n",
    "class WeatherData(Base):\n",
    "    __tablename__ = 'weather_data'\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    city = Column(String, index=True)\n",
    "    state = Column(String, index=True)\n",
    "    date = Column(Date, index=True)\n",
    "    temperature = Column(Float)\n",
    "    time_start = Column(String)\n",
    "    time_end = Column(String)\n",
    "    timestamp = Column(DateTime, default=datetime.datetime.now(datetime.timezone.utc))\n",
    "\n",
    "\n",
    "# Create the database and tables\n",
    "def create_database():\n",
    "    engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "    Base.metadata.create_all(bind=engine)\n",
    "    print(\"Database and tables created.\")\n",
    "\n",
    "# Drop all tables in the database\n",
    "def reset_database():\n",
    "    engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "    Base.metadata.drop_all(bind=engine)\n",
    "    Base.metadata.create_all(bind=engine)\n",
    "    print(\"Database reset complete.\")\n",
    "\n",
    "# Custom session to handle API fetching if data is missing\n",
    "class CustomSession(Session):\n",
    "    def query_with_api(self, model, request):\n",
    "        try:\n",
    "            # Attempt to retrieve data from the database\n",
    "            result = self.query(model).filter_by(**request).all()\n",
    "            if result:\n",
    "                return result\n",
    "            else:\n",
    "                raise NoResultFound\n",
    "        except NoResultFound:\n",
    "            # If data is not found, fetch from the API and store it\n",
    "            if model == ElectricityData:\n",
    "                tool = ElectricityPriceTool(self)\n",
    "                tool.get_electricity_prices(request)\n",
    "            elif model == WeatherData:\n",
    "                tool = WeatherDataTool(self)\n",
    "                tool.get_weather_data(request)\n",
    "            # Attempt to retrieve data again after fetching from the API\n",
    "            result = self.query(model).filter_by(**request).all()\n",
    "            return result\n",
    "\n",
    "\n",
    "def get_db():\n",
    "    # Use the custom session\n",
    "    engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine, class_=CustomSession)\n",
    "    try:\n",
    "        db = SessionLocal()\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "def store_data(db, model, data):\n",
    "    for item in data:\n",
    "        item['date'] = datetime.strptime(item['date'], '%Y-%m-%d').date()  # Correct usage\n",
    "        db_item = model(**item)\n",
    "        db.add(db_item)\n",
    "    db.commit()\n",
    "\n",
    "# Example usage to reset the database\n",
    "if __name__ == \"__main__\":\n",
    "    reset_database()  # Resets the database (drops and recreates tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schemas.py\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class ElPriceResponse(BaseModel):\n",
    "    NOK_per_kWh: float\n",
    "    EUR_per_kWh: float\n",
    "    EXR: float\n",
    "    time_start: str\n",
    "    time_end: str\n",
    "\n",
    "    class Config:\n",
    "        from_attributes = True\n",
    "\n",
    "class ElPriceRequest(BaseModel):\n",
    "    city: str = Field(description=\"City\")\n",
    "    state: str = Field(description=\"State or region\")\n",
    "    date: str = Field(description=\"Date query ('YYYY-MM-DD/YYYY-MM-DD')\")\n",
    "\n",
    "# Pydantic models\n",
    "class WeatherDataResponse(BaseModel):\n",
    "    temperature: float\n",
    "    time_start: str\n",
    "    time_end: str\n",
    "\n",
    "    class Config:\n",
    "        from_attributes = True\n",
    "\n",
    "class WeatherRequest(BaseModel):\n",
    "    city: str = Field(description=\"City\")\n",
    "    state: str = Field(description=\"State or region\")\n",
    "    date: str = Field(description=\"Date query (YYYY-MM-DD/YYYY-MM-DD')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from geopy.distance import geodesic\n",
    "from geopy.geocoders import Nominatim\n",
    "import requests_cache\n",
    "import openmeteo_requests\n",
    "import pandas as pd\n",
    "from sqlalchemy.orm import Session\n",
    "from functools import lru_cache\n",
    "from retry_requests import retry\n",
    "\n",
    "# Utility function to parse date ranges\n",
    "def parse_date(date: str) -> Tuple[datetime, datetime]:\n",
    "    try:\n",
    "        if '/' in date:\n",
    "            start_date_str, end_date_str = date.split('/')\n",
    "            start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "            end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "        else:\n",
    "            start_date = end_date = datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "        if start_date > end_date:\n",
    "            raise ValueError(\"Start date cannot be after end date.\")\n",
    "\n",
    "        return start_date, end_date\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format: {date}. Expected format is YYYY-MM-DD or YYYY-MM-DD/YYYY-MM-DD. Error: {str(e)}\")\n",
    "\n",
    "\n",
    "# Base class to handle common methods\n",
    "class BaseDataTool:\n",
    "    geolocator = Nominatim(user_agent=\"data_tool_api\")\n",
    "\n",
    "    def __init__(self, db: Session):\n",
    "        self.db = db\n",
    "\n",
    "    @lru_cache(maxsize=100)\n",
    "    def get_coordinates(self, city_name: str, state: str) -> Optional[Tuple[float, float]]:\n",
    "        location = self.geolocator.geocode(f\"{city_name}, {state}\")\n",
    "        return (location.latitude, location.longitude) if location else None\n",
    "\n",
    "\n",
    "# Tool to fetch electricity prices\n",
    "class ElectricityPriceTool(BaseDataTool):\n",
    "    REGIONS = {\n",
    "        \"NO1\": (\"Oslo\", (59.9139, 10.7522)),\n",
    "        \"NO2\": (\"Kristiansand\", (58.1467, 7.9956)),\n",
    "        \"NO3\": (\"Trondheim\", (63.4305, 10.3951)),\n",
    "        \"NO4\": (\"TromsÃ¸\", (69.6492, 18.9553)),\n",
    "        \"NO5\": (\"Bergen\", (60.3928, 5.3221)),\n",
    "    }\n",
    "\n",
    "    session = requests_cache.CachedSession('electricity_cache', expire_after=86400)\n",
    "\n",
    "    def find_nearest_region(self, lat: float, lon: float) -> Optional[str]:\n",
    "        nearest_region = min(\n",
    "            self.REGIONS.items(),\n",
    "            key=lambda region: geodesic((lat, lon), region[1][1]).kilometers\n",
    "        )[0]\n",
    "        return nearest_region\n",
    "\n",
    "    def fetch_electricity_prices(self, date: str, region: str) -> list:\n",
    "        year, month, day = date.split('-')\n",
    "        url = f\"https://www.hvakosterstrommen.no/api/v1/prices/{year}/{month}-{day}_{region}.json\"\n",
    "        response = self.session.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        return {\"error\": f\"Error fetching data: {response.status_code}\"}\n",
    "\n",
    "    def store_prices(self, request: Dict[str, Any], region: str, prices: list):\n",
    "        data = [\n",
    "            {\n",
    "                \"city\": request['city'],\n",
    "                \"state\": request['state'],\n",
    "                \"date\": datetime.strptime(request['date'], '%Y-%m-%d').date(),\n",
    "                \"region\": region,\n",
    "                \"NOK_per_kWh\": price[\"NOK_per_kWh\"],\n",
    "                \"EUR_per_kWh\": price[\"EUR_per_kWh\"],\n",
    "                \"EXR\": price[\"EXR\"],\n",
    "                \"time_start\": datetime.fromisoformat(price[\"time_start\"]),\n",
    "                \"time_end\": datetime.fromisoformat(price[\"time_end\"])\n",
    "            }\n",
    "            for price in prices\n",
    "        ]\n",
    "        \n",
    "        self.db.bulk_save_objects([ElectricityData(**entry) for entry in data])\n",
    "        self.db.commit()\n",
    "\n",
    "    def get_electricity_prices(self, request: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        coordinates = self.get_coordinates(request['city'], request['state'])\n",
    "        if not coordinates:\n",
    "            return {\"error\": \"City not found\"}\n",
    "\n",
    "        lat, lon = coordinates\n",
    "        start_date, end_date = parse_date(request['date'])\n",
    "        nearest_region = self.find_nearest_region(lat, lon)\n",
    "        all_prices = []\n",
    "\n",
    "        if nearest_region:\n",
    "            current_date = start_date\n",
    "            while current_date <= end_date:\n",
    "                date_str = current_date.strftime('%Y-%m-%d')\n",
    "                prices = self.fetch_electricity_prices(date_str, nearest_region)\n",
    "                if isinstance(prices, list):\n",
    "                    self.store_prices({**request, 'date': date_str}, nearest_region, prices)\n",
    "                    all_prices.extend(prices)\n",
    "                current_date += timedelta(days=1)\n",
    "\n",
    "            return all_prices if all_prices else {\"error\": \"No data found for the given date range.\"}\n",
    "\n",
    "        return {\"error\": \"Could not determine the nearest region.\"}\n",
    "\n",
    "\n",
    "class WeatherDataTool(BaseDataTool):\n",
    "    cache_session = requests_cache.CachedSession('.weather_cache', expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    def store_weather_data(self, request: Dict[str, Any], observations: list):\n",
    "        data = [\n",
    "            {\n",
    "                \"city\": request['city'],\n",
    "                \"state\": request['state'],\n",
    "                \"date\": datetime.strptime(observation['date'], '%Y-%m-%d').date(),\n",
    "                \"temperature\": observation['temperature'],\n",
    "                \"time_start\": datetime.fromisoformat(observation['time_start']),\n",
    "                \"time_end\": datetime.fromisoformat(observation['time_end']),\n",
    "            }\n",
    "            for observation in observations\n",
    "        ]\n",
    "        self.db.bulk_save_objects([WeatherData(**entry) for entry in data])\n",
    "        self.db.commit()\n",
    "\n",
    "    def get_weather_data(self, request: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        coordinates = self.get_coordinates(request['city'], request['state'])\n",
    "        if not coordinates:\n",
    "            return {\"error\": \"Could not find coordinates for the specified city and state.\"}\n",
    "\n",
    "        latitude, longitude = coordinates\n",
    "        start_date, end_date = parse_date(request['date'])\n",
    "\n",
    "        all_observations =\n",
    "# Tool to fetch electricity prices\n",
    "class ElectricityPriceTool(BaseDataTool):\n",
    "    REGIONS = {\n",
    "        \"NO1\": (\"Oslo\", (59.9139, 10.7522)),\n",
    "        \"NO2\": (\"Kristiansand\", (58.1467, 7.9956)),\n",
    "        \"NO3\": (\"Trondheim\", (63.4305, 10.3951)),\n",
    "        \"NO4\": (\"TromsÃ¸\", (69.6492, 18.9553)),\n",
    "        \"NO5\": (\"Bergen\",  []\n",
    "        current_date = start_date\n",
    "\n",
    "        while current_date <= end_date:\n",
    "            date_str = current_date.strftime('%Y-%m-%d')\n",
    "            params = {\n",
    "                \"latitude\": latitude,\n",
    "                \"longitude\": longitude,\n",
    "                \"start_date\": date_str,\n",
    "                \"end_date\": date_str,\n",
    "                \"hourly\": \"temperature_2m\"\n",
    "            }\n",
    "            response = self.openmeteo.weather_api(\"https://archive-api.open-meteo.com/v1/archive\", params=params)[0]\n",
    "\n",
    "            hourly = response.Hourly()\n",
    "            hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "\n",
    "            hourly_dates = pd.date_range(\n",
    "                start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "                end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "                freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "                inclusive=\"left\"\n",
    "            ).strftime('%Y-%m-%dT%H:%M:%S%z')\n",
    "\n",
    "            observations = [\n",
    "                {\n",
    "                    \"date\": date_str,\n",
    "                    \"temperature\": float(hourly_temperature_2m[i]),\n",
    "                    \"time_start\": hourly_dates[i],\n",
    "                    \"time_end\": hourly_dates[i + 1]\n",
    "                }\n",
    "                for i in range(len(hourly_dates) - 1)\n",
    "            ]\n",
    "\n",
    "            all_observations.extend(observations)\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "        self.store_weather_data(request, all_observations)\n",
    "\n",
    "        return all_observations\n",
    "\n",
    "\n",
    "# Example request for electricity prices\n",
    "def get_all_electricity_prices(db: Session, electricity_request: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    tool = ElectricityPriceTool(db)\n",
    "    return tool.get_electricity_prices(electricity_request)\n",
    "\n",
    "\n",
    "# Example request for weather data\n",
    "def get_all_weather_data(db: Session, weather_request: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    tool = WeatherDataTool(db)\n",
    "    return tool.get_weather_data(weather_request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sqlalchemy.orm import Session\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Fetch electricity prices and convert to DataFrame\n",
    "def convert_el_to_df(db: Session, electricity_request: Dict[str, Any]) -> pd.DataFrame:\n",
    "    data = get_all_electricity_prices(db, electricity_request)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Fetch weather data and convert to DataFrame\n",
    "def convert_weather_to_df(db: Session, weather_request: Dict[str, Any]) -> pd.DataFrame:\n",
    "    data = get_all_weather_data(db, weather_request)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "\n",
    "def process_electricity_prices(prices: List[ElPriceResponse]):\n",
    "    if all(isinstance(price, dict) for price in prices):\n",
    "        return prices\n",
    "    else:\n",
    "        return [price.dict() for price in prices]\n",
    "\n",
    "\n",
    "def process_weather_data(data: List[WeatherDataResponse]) -> List[Dict[str, Any]]:\n",
    "    if all(isinstance(item, dict) for item in data):\n",
    "        return data\n",
    "    else:    \n",
    "        return [item.dict() for item in data]\n",
    "\n",
    "def query_electricity_prices(db: Session, city: str, state: str, date: str) -> List[Dict[str, Any]]:\n",
    "    prices = get_all_electricity_prices(db, {\"city\": city, \"state\": state, \"date\": date})\n",
    "    # Convert to a list of dictionaries\n",
    "    return process_electricity_prices(prices)\n",
    "\n",
    "def query_weather_data(db: Session, city: str, state: str, date: str) -> List[Dict[str, Any]]:\n",
    "    request = {\"city\": city, \"state\": state, \"date\": date}\n",
    "    weather_data = get_all_weather_data(db, request)\n",
    "    return process_weather_data(weather_data)\n",
    "\n",
    "@tool\n",
    "def electricity_price_tool(city: str, state: str, date: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetches electricity prices for a given city, state, and date query.\n",
    "\n",
    "    \"\"\"\n",
    "    with next(get_db()) as db:\n",
    "        prices = query_electricity_prices(db, city, state, date)\n",
    "    return prices\n",
    "\n",
    "@tool\n",
    "def weather_data_tool(city: str, state: str, date: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetches weather data for a given city, state, and date query.\n",
    "\n",
    "    \"\"\"\n",
    "    with next(get_db()) as db:\n",
    "        weather_data = query_weather_data(db, city, state, date)\n",
    "    return weather_data\n",
    "\n",
    "\n",
    "# Fishing tools (data retrieval)\n",
    "fishing_tools = [electricity_price_tool, weather_data_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "db = SQLDatabase(engine)\n",
    "\n",
    "# Assuming `db` is your database session and `llm` is your language model\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "# SQL tools (data analysis)\n",
    "sql_tools = toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch electricity prices and convert to DataFrame\n",
    "def query_el_to_df(db: Session, electricity_request: Dict[str, Any]) -> pd.DataFrame:\n",
    "    data = get_all_electricity_prices(db, electricity_request)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Fetch weather data and convert to DataFrame\n",
    "def query_weather_to_df(db: Session, weather_request: Dict[str, Any]) -> pd.DataFrame:\n",
    "    data = get_all_weather_data(db, weather_request)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def correlation_analysis(db: Session, electricity_request: Dict[str, Any], weather_request: Dict[str, Any]) -> float:\n",
    "    electricity_df = query_el_to_df(db, electricity_request)\n",
    "    weather_df = query_weather_to_df(db, weather_request)\n",
    "    \n",
    "    correlation = electricity_df['NOK_per_kWh'].corr(weather_df['temperature'])\n",
    "    \n",
    "    return correlation\n",
    "\n",
    "def descriptive_statistics(db: Session, electricity_request: Dict[str, Any], weather_request: Dict[str, Any]) -> Dict[str, pd.DataFrame]:\n",
    "    electricity_df = query_el_to_df(db, electricity_request)\n",
    "    weather_df = query_weather_to_df(db, weather_request)\n",
    "    \n",
    "    electricity_stats = electricity_df.describe()\n",
    "    weather_stats = weather_df.describe()\n",
    "    \n",
    "    return {\"electricity_stats\": electricity_stats, \"weather_stats\": weather_stats}\n",
    "\n",
    "def regression_analysis(db: Session, electricity_request: Dict[str, Any], weather_request: Dict[str, Any]) -> str:\n",
    "    electricity_df = query_el_to_df(db, electricity_request)\n",
    "    weather_df = query_weather_to_df(db, weather_request)\n",
    "    \n",
    "    merged_df = pd.merge(electricity_df, weather_df, on=['city', 'state', 'date'])\n",
    "    \n",
    "    merged_df['date_numeric'] = pd.to_datetime(merged_df['date']).map(pd.Timestamp.timestamp)\n",
    "    \n",
    "    X = merged_df['date_numeric']\n",
    "    \n",
    "    Y_temp = merged_df['temperature']\n",
    "    Y_price = merged_df['NOK_per_kWh']\n",
    "    \n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    model_temp = sm.OLS(Y_temp, X).fit()\n",
    "    model_price = sm.OLS(Y_price, X).fit()\n",
    "    \n",
    "    summary_temp = f\"Temperature Regression:\\nR-squared: {model_temp.rsquared:.4f}, p-value: {model_temp.f_pvalue:.4f}\\n\"\n",
    "    summary_price = f\"Electricity Price Regression:\\nR-squared: {model_price.rsquared:.4f}, p-value: {model_price.f_pvalue:.4f}\\n\"\n",
    "    \n",
    "    return f\"{summary_temp}\\n{summary_price}\"\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def descriptive_stats_tool(city: str, state: str, date: str) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Computes descriptive statistics for electricity prices and weather data.\n",
    "\n",
    "    Args:\n",
    "        city (str): The city for which the data is requested.\n",
    "        state (str): The state or region for the requested city.\n",
    "        date (str): The date or date range in 'YYYY-MM-DD' or 'YYYY-MM-DD/YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: A dictionary containing descriptive statistics for electricity prices \n",
    "        and weather data, with keys 'electricity_stats' and 'weather_stats' respectively.\n",
    "    \"\"\"\n",
    "    with next(get_db()) as db:\n",
    "        electricity_request = {\"city\": city, \"state\": state, \"date\": date}\n",
    "        weather_request = {\"city\": city, \"state\": state, \"date\": date}\n",
    "        stats = descriptive_statistics(db, electricity_request, weather_request)\n",
    "    return stats\n",
    "\n",
    "\n",
    "@tool\n",
    "def correlation_tool(city: str, state: str, date: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the correlation between electricity prices and temperature.\n",
    "\n",
    "    Args:\n",
    "        city (str): The city for which the data is requested.\n",
    "        state (str): The state or region for the requested city.\n",
    "        date (str): The date or date range in 'YYYY-MM-DD' or 'YYYY-MM-DD/YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "        float: The correlation coefficient between electricity prices (NOK_per_kWh) and temperature.\n",
    "    \"\"\"\n",
    "    with next(get_db()) as db:\n",
    "        electricity_request = {\"city\": city, \"state\": state, \"date\": date}\n",
    "        weather_request = {\"city\": city, \"state\": state, \"date\": date}\n",
    "        correlation = correlation_analysis(db, electricity_request, weather_request)\n",
    "    return correlation\n",
    "\n",
    "\n",
    "@tool\n",
    "def regression_tool(city: str, state: str, date: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a linear regression analysis on the relationship between electricity prices and temperature.\n",
    "\n",
    "    Args:\n",
    "        city (str): The city for which the data is requested.\n",
    "        state (str): The state or region for the requested city.\n",
    "        date (str): The date or date range in 'YYYY-MM-DD' or 'YYYY-MM-DD/YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "        str: A summary of the regression analysis as a formatted string.\n",
    "    \"\"\"\n",
    "    with next(get_db()) as db:\n",
    "        electricity_request = {\"city\": city, \"state\": state, \"date\": date}\n",
    "        weather_request = {\"city\": city, \"state\": state, \"date\": date}\n",
    "        regression_summary = regression_analysis(db, electricity_request, weather_request)\n",
    "    return regression_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_tools = [regression_tool, correlation_tool, descriptive_stats_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = sql_tools + fishing_tools + statistical_tools\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 'electricity_prices' table:\n",
      "id\n",
      "city\n",
      "state\n",
      "date\n",
      "region\n",
      "NOK_per_kWh\n",
      "EUR_per_kWh\n",
      "EXR\n",
      "time_start\n",
      "time_end\n",
      "timestamp\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    inspector = inspect(engine)\n",
    "    columns = inspector.get_columns('electricity_prices')\n",
    "    print(\"Columns in 'electricity_prices' table:\")\n",
    "    for column in columns:\n",
    "        print(column['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_prompt = SystemMessage(content=\"You are an AI that specializes in analyzing electricity prices and weather data. Your responses should be concise, data-driven, and insightful. Provide statistical analyses where relevant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke([system_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Step 1: Create the primary assistant prompt template\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant specializing in data analysis with a focus on electricity prices and weather data. \"\n",
    "            \"Follow these steps to fulfill user requests:\\n\"\n",
    "            \"1. **Determine Data Requirements**: Understand the user's query and identify the type of data needed (e.g., electricity prices, weather data).\\n\"\n",
    "            \"2. **Check Data Availability**: Use the SQL tools to check if the required data is already available in the database.\\n\"\n",
    "            \"   - If data is available, fetch it using the SQL tools.\\n\"\n",
    "            \"   - If data is not available, use the appropriate fetching tools to obtain the data (e.g., electricity_price_tool, weather_data_tool).\\n\"\n",
    "            \"3. **Data Analysis**: Once data is obtained, determine the type of statistical analysis required by the user (e.g., descriptive statistics, correlation, regression).\\n\"\n",
    "            \"   - Use the descriptive_stats_tool for basic statistical summaries.\\n\"\n",
    "            \"   - Use the correlation_tool to analyze relationships between variables.\\n\"\n",
    "            \"   - Use the regression_tool for predictive modeling and to understand relationships between variables.\\n\"\n",
    "            \"4. **Provide Insightful Responses**: Offer concise, data-driven insights and visualizations as needed based on the analysis results. Always ensure your responses are clear, precise, and aligned with the user's query.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),  # Placeholder to be replaced by actual user messages dynamically.\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Step 2: Bind tools to the LLM\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    ")\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools):\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "def handle_tool_error(state):\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=f\"Error: {repr(error)}. Please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"]\n",
    "            ) for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "tool_node_with_fallback = create_tool_node_with_fallback(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        \"\"\"\n",
    "        Initialize the Assistant with a runnable object.\n",
    "\n",
    "        Args:\n",
    "            runnable (Runnable): The runnable instance to invoke.\n",
    "        \"\"\"\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        \"\"\"\n",
    "        Call method to invoke the LLM and handle its responses.\n",
    "        Re-prompt the assistant if the response is not a tool call or meaningful text.\n",
    "\n",
    "        Args:\n",
    "            state (State): The current state containing messages.\n",
    "            config (RunnableConfig): The configuration for the runnable.\n",
    "\n",
    "        Returns:\n",
    "            dict: The final state containing the updated messages.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)  # Invoke the LLM\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", Assistant(assistant_runnable))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "#memory = MemorySaver()\n",
    "app = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " Can you fettch the weather data in Trondheim in the period between 2024-06-01 and 2024-07-16. Calculate the correlation with the data from sql database\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  correlation_tool (call_ANkoQ5AMz5KEMhScKsghcNS1)\n",
      " Call ID: call_ANkoQ5AMz5KEMhScKsghcNS1\n",
      "  Args:\n",
      "    city: Trondheim\n",
      "    state: Norway\n",
      "    date: 2024-06-01/2024-07-16\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: correlation_tool\n",
      "\n",
      "0.1427463039886295\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The correlation coefficient between electricity prices and temperature in Trondheim from June 1, 2024, to July 16, 2024, is approximately 0.14. This indicates a weak positive correlation between electricity prices and temperature during this period.\n"
     ]
    }
   ],
   "source": [
    "def process_input(input_text):\n",
    "    # Streaming the response from the app based on input_text\n",
    "    for chunk in app.stream(\n",
    "        {\"messages\": [(\"human\", input_text)]}, \n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# Example usage with a single input\n",
    "process_input(\" Can you fettch the weather data in Trondheim in the period between 2024-06-01 and 2024-07-16. Calculate the correlation with the data from sql database\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": ".myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
